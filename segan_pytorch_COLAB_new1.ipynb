{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segan-pytorch-COLAB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3hyukl8d5wkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SEGAN pytorch implementation\n",
        "by Hyungon Ryu | Sr. Solution Architect in Korea\n"
      ]
    },
    {
      "metadata": {
        "id": "L50v_qzwdrjk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This jupyter implement  of [SEGAN-PyT](https://github.com/yhgon/segan-pyt) which is similar as [SEGAN-TF](https://github.com/santi-pdp/segan) project  in COLAB. The original paper can be found [here](https://arxiv.org/abs/1703.09452) , and there are two SEGAN PyTorch implementation : \n",
        " - [leftthomas' SEGAN-PyT ](https://github.com/leftthomas/SEGAN)\n",
        " - [deNsuh' SEGAN-PyT ](https://github.com/deNsuh/segan-pytorch)\n",
        "\n",
        "![SEGAN model image](https://github.com/santi-pdp/segan/raw/master/assets/segan_g.png)\n",
        "\n",
        "This model deals with raw speech waveforms on many noise conditions at different SNRs (40 at training time and 20 during test). It also models the speech characteristics from many speakers mixed within the same structure (without any supervision of identities), which makes the generative structure generalizable in the noise and speaker dimensions.\n",
        "\n",
        "There are two repositories that were good references on how GANs are defined and deployed:\n",
        "\n",
        "  - [OpenAI's improved-gan](https://github.com/openai/improved-gan): implementing improvements to train GANs in a more stable way\n",
        "  - [Carpedm20's DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow): implementation of the DCGAN in tensorflow\n",
        " \n",
        "  - [Rafael's vNorm ](https://discuss.pytorch.org/t/parameter-grad-of-conv-weight-is-none-after-virtual-batch-normalization/9036) implementation of virtual Batch Normalization\n",
        " \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "OpDIJBfv52hn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DevOps \n",
        "for using pytorch in COLAB, we need to check exact CUDA libraries and pytorch binaries.\n",
        "\n",
        "### step1. network install CUDA 9.0 libraries \n"
      ]
    },
    {
      "metadata": {
        "id": "dXoWZ1Ja24er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "bb91382a-ede7-4ded-9629-d7c4ac4a1fc0"
      },
      "cell_type": "code",
      "source": [
        "!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/cuda-repo-ubuntu1704_9.0.176-1_amd64.deb\n",
        "!apt-get install dirmngr\n",
        "!dpkg -i cuda-repo-ubuntu1704_9.0.176-1_amd64.deb\n",
        "!apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install  -y --no-install-recommends  \\\n",
        " cuda-core-9-0 \\\n",
        " cuda-cublas-9-0 cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 \\\n",
        " cuda-cufft-9-0 cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 \\\n",
        " cuda-cusolver-9-0 cuda-cusolver-dev-9-0 cuda-cusparse-9-0 \\\n",
        " cuda-cusparse-dev-9-0 \\\n",
        " cuda-libraries-9-0 cuda-libraries-dev-9-0 \\\n",
        " cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 \\\n",
        " cuda-nvgraph-9-0 cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 \\\n",
        " cuda-nvrtc-dev-9-0 "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.1’.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "dirmngr is already the newest version (2.1.15-1ubuntu8.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "(Reading database ... 19751 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1704_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1704 (9.0.176-1) over (9.0.176-1) ...\n",
            "Setting up cuda-repo-ubuntu1704 (9.0.176-1) ...\n",
            "Executing: /tmp/apt-key-gpghome.qfre4qwlMG/gpg.1.sh --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub\n",
            "gpg: requesting key from 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64/7fa2af80.pub'\n",
            "gpg: key F60F4B3D7FA2AF80: \"cudatools <cudatools@nvidia.com>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Hit:1 http://security.ubuntu.com/ubuntu artful-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu artful InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu artful-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu artful-backports InRelease\n",
            "Ign:5 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64  InRelease\n",
            "Hit:6 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1704/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-core-9-0 is already the newest version (9.0.176.3-1).\n",
            "cuda-cudart-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cudart-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cufft-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cufft-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-curand-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-curand-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cusolver-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cusolver-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cusparse-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cusparse-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-libraries-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-libraries-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-misc-headers-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-npp-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-npp-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-nvgraph-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-nvgraph-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-nvml-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-nvrtc-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-nvrtc-dev-9-0 is already the newest version (9.0.176-1).\n",
            "cuda-cublas-9-0 is already the newest version (9.0.176.4-1).\n",
            "cuda-cublas-dev-9-0 is already the newest version (9.0.176.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "it8zMFMI2126",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### step2. pytorch installation for python3.6\n"
      ]
    },
    {
      "metadata": {
        "id": "bqm_IlVC-n8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "5b92d44a-8318-4be6-9a91-80d4fe6c15c0"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision\n",
        "#below link is slower than files.pythonhosted.org but same file\n",
        "#!pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 30kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5a064000 @  0x7fa9513ca1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "398mwBIi23pX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "876b8498-fe55-4ba1-dbc3-34d1f790f102"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install   librosa tqdm  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting librosa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/b4/5b411f19de48f8fc1a0ff615555aa9124952e4156e94d4803377e50cfa4c/librosa-0.6.2.tar.gz (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.26.0)\n",
            "Collecting audioread>=2.0.0 (from librosa)\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/41/8cd160c6b2046b997d571a744a7f398f39e954a62dd747b2aae1ad7f07d4/audioread-2.1.6.tar.gz\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.19.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.19.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Collecting resampy>=0.2.0 (from librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b6/66a06d85474190b50aee1a6c09cdc95bb405ac47338b27e9b21409da1760/resampy-0.2.1.tar.gz (322kB)\n",
            "\u001b[K    100% |████████████████████████████████| 327kB 25.8MB/s \n",
            "\u001b[?25hCollecting numba>=0.38.0 (from librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/ac/c87f229ae7f29fbf85bc5405f85ec7097c979c021dac52f2d5206834a899/numba-0.40.0-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.4MB 9.8MB/s \n",
            "\u001b[?25hCollecting llvmlite>=0.25.0dev0 (from numba>=0.38.0->librosa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/fb/f9c2e9e0ef2b54c52f0b727cf6af75b68c3d7ddb6d88c8d557b1b16bc1ab/llvmlite-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (16.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 16.1MB 2.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: librosa, audioread, resampy\n",
            "  Running setup.py bdist_wheel for librosa ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/18/b8/10/f0f8f6ac60668a5cd75596cf14c25bb6b3ea1ecd815f058b7e\n",
            "  Running setup.py bdist_wheel for audioread ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/53/02/90/7b5c4081b7470c550ab605f600bad237dde12a6b8999b11f50\n",
            "  Running setup.py bdist_wheel for resampy ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ff/4f/ed/2e6c676c23efe5394bb40ade50662e90eb46e29b48324c5f9b\n",
            "Successfully built librosa audioread resampy\n",
            "Installing collected packages: audioread, llvmlite, numba, resampy, librosa\n",
            "Successfully installed audioread-2.1.6 librosa-0.6.2 llvmlite-0.25.0 numba-0.40.0 resampy-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RPRWGaXoCReF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### step2. pytorch installation for python3.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yqt9VsyKCSdH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### step3. check the system\n",
        "with nvidia-smi, you could check GPU is avalable.\n",
        "if you have prolem,  in the menu of jupyter notebook `EDIT > Notebook Settings` and check the Accelerator for `GPU`"
      ]
    },
    {
      "metadata": {
        "id": "Wim1HTV3AXg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "a82b39b6-de39-4c3d-d857-1ea365f8456d"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct  3 12:59:02 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    31W / 149W |      0MiB / 11439MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1I8HYlus9zb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "05011f81-264d-4534-e270-90e3744f2678"
      },
      "cell_type": "code",
      "source": [
        "#pytorch verification code\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print('Check computation\\n',x)\n",
        "print('Check GPU is available : ',torch.cuda.is_available())\n",
        "print('CuDNN version : ', torch.backends.cudnn.version())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check computation\n",
            " tensor([[0.6055, 0.1374, 0.2097],\n",
            "        [0.6046, 0.6662, 0.1934],\n",
            "        [0.3607, 0.1231, 0.3689],\n",
            "        [0.5207, 0.9183, 0.8511],\n",
            "        [0.2108, 0.9905, 0.2923]])\n",
            "Check GPU is available :  True\n",
            "CuDNN version :  7102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVb0xcV5Bkpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b631b78-e8ca-4f0f-9764-1aad67a2b4df"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi | grep MiB"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| N/A   34C    P8    31W / 149W |     11MiB / 11439MiB |      0%      Default |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A_KVJxD9I4UZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# prepare Dataset\n",
        "\n",
        "## Dataset\n",
        "The speech enhancement dataset used can be found in [Edinburgh DataShare](http://datashare.is.ed.ac.uk/handle/10283/1942).  In COLAB environment, you will lose the downloaded dataset in every reconnection. So I recommend to mount google drive in COLAB. for each connection, a time for each connection in COLAB.\n",
        "\n",
        "\n",
        "There are [GUIDE](https://colab.research.google.com/notebooks/io.ipynb) and example for External data: Drive, Sheets, and Cloud Storage in COLAB\n",
        "\n",
        "\n",
        "There are three dataset I'll use 48khz dataset base on original segan tensorflow implmentation to save storage\n",
        " - [48khz dataset](http://datashare.is.ed.ac.uk/handle/10283/1942)\n",
        " - [56khz and 28khz dataset](https://datashare.is.ed.ac.uk/handle/10283/2791)\n",
        "\n",
        "I assume you already upload below 4 files in google drive \n",
        " - clean_testset_wav.zip\t\n",
        " - noisy_testset_wav.zip\n",
        " - clean_trainset_wav.zip\t\n",
        " - noisy_trainset_wav.zip\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "msEqDw5Ux7s6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "79a6fda0-abaf-48b0-a7d9-afe7f9d86bf8"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2cXeLfEiyMbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "68617391-ed19-45bc-c81a-79f0b44c7c8c"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!rm -rf ./dataset-segan\n",
        "!ls -h   \"drive/My Drive/COLAB/segan/\"\n",
        "!mkdir ./dataset-segan\n",
        "!cp  -rf \"drive/My Drive/COLAB/segan/clean_testset_wav.zip\" ./dataset-segan/.\n",
        "!cp  -rf \"drive/My Drive/COLAB/segan/noisy_testset_wav.zip\" ./dataset-segan/.\n",
        "!cp  -rf \"drive/My Drive/COLAB/segan/clean_trainset_wav.zip\" ./dataset-segan/.\n",
        "!cp  -rf \"drive/My Drive/COLAB/segan/noisy_trainset_wav.zip\" ./dataset-segan/.\n",
        "!ls -h ./dataset-segan"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_testset_wav.zip\tnoisy_testset_wav.zip\tsegan.tfrecords\n",
            "clean_trainset_wav.zip\tnoisy_trainset_wav.zip\n",
            "clean_testset_wav.zip\tnoisy_testset_wav.zip\n",
            "clean_trainset_wav.zip\tnoisy_trainset_wav.zip\n",
            "CPU times: user 418 ms, sys: 92.9 ms, total: 511 ms\n",
            "Wall time: 46.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wCRTiUDYybyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1aae1832-cde6-415b-aacd-bc98ad505c78"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!mkdir data\n",
        "!unzip -q ./dataset-segan/clean_trainset_wav.zip -d ./data/clean_trainset_wav\n",
        "!unzip -q ./dataset-segan/clean_testset_wav.zip  -d ./data\n",
        "!unzip -q ./dataset-segan/noisy_trainset_wav.zip -d ./data/noisy_trainset_wav\n",
        "!unzip -q ./dataset-segan/noisy_testset_wav.zip  -d ./data\n",
        "!du -h data\n",
        "!ls ./data/clean_trainset_wav | head -n 2\n",
        "!ls ./data/clean_testset_wav  | head -n 2\n",
        "!ls ./data/noisy_trainset_wav | head -n 2\n",
        "!ls ./data/noisy_testset_wav  | head -n 2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "192M\tdata/noisy_testset_wav\n",
            "1.1G\tdata/clean_trainset_wav\n",
            "192M\tdata/clean_testset_wav\n",
            "1.1G\tdata/noisy_trainset_wav\n",
            "2.5G\tdata\n",
            "p226_001.wav\n",
            "p226_002.wav\n",
            "p232_001.wav\n",
            "p232_002.wav\n",
            "p226_001.wav\n",
            "p226_002.wav\n",
            "p232_001.wav\n",
            "p232_002.wav\n",
            "CPU times: user 549 ms, sys: 111 ms, total: 660 ms\n",
            "Wall time: 59 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Av9v_qF6IXaB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## clone the SEGAN model and utilities\n",
        "The origianl SEGAN implementation based old pytorch so I've  modify few word for compatability with COLAB which use python version 3.6.3 \n",
        "you could check\n",
        "\n",
        "\n",
        " [diff1 1ded4f0 ](https://github.com/yhgon/segan-pyt/commit/1ded4f0c15bffe51027bb78e8a63aa25afbfded9)\n",
        "```\n",
        "in data_preprocess.py\n",
        "7  -  clean_train_folder = 'data/clean_trainset_56spk_wav'\n",
        "8  -  noisy_train_folder = 'data/noisy_trainset_56spk_wav'\n",
        "7  +  clean_train_folder = 'data/clean_trainset_wav'\n",
        "8  + noisy_train_folder = 'data/noisy_trainset_wav'\n",
        " ```\n",
        " \n",
        "\n",
        " [diff2 d1e70f ](https://github.com/yhgon/segan-pyt/commit/d1e70ffe67a9d3e2cbfe4bd48d90948b75693cf3)\n",
        "```\n",
        "model.py\n",
        " 21 -      self.gamma = Parameter(torch.normal(means=torch.ones(1, num_features, 1), std=0.02))\n",
        " 21 +      self.gamma = Parameter(torch.normal(mean=torch.ones(1, num_features, 1), std=0.02))\n",
        " ```\n",
        "[diff3 44fe049 ](https://github.com/yhgon/segan-pyt/commit/44fe04947e8f1ea580295d877207908b5fba851b)\n",
        "```\n",
        "in model.py\n",
        "166 -  nn.init.xavier_normal(m.weight.data)\n",
        " 166 + nn.init.xavier_normal_(m.weight.data)\n",
        " \n",
        " 278 -  nn.init.xavier_normal(m.weight.data)\n",
        " 276 +  nn.init.xavier_normal_(m.weight.data)\n",
        " ```\n",
        " \n",
        " [diff4 991db35 ](https://github.com/yhgon/segan-pyt/commit/991db3581a95b71bcbe476daf1cb3c30b4e80b80)\n",
        "```\n",
        "in main.py\n",
        " 53  -  z = nn.init.normal(torch.Tensor(train_batch.size(0), 1024, 8))\n",
        " 53  +  z = nn.init.normal_(torch.Tensor(train_batch.size(0), 1024, 8))\n",
        " ```\n",
        " \n",
        " \n",
        " [diff5 bdbe9f3 ](https://github.com/yhgon/segan-pyt/commit/bdbe9f3e3ff337ab13f065abd0d37de6ca63e9cf)\n",
        "```\n",
        "in main.py\n",
        "99 -  z = nn.init.normal(torch.Tensor(test_noisy.size(0), 1024, 8))\n",
        "99 +  z = nn.init.normal_(torch.Tensor(test_noisy.size(0), 1024, 8)) \n",
        "```\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "zktG08VwvwB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "c720568a-802e-495c-80a0-23bf467693cf"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf segan-pyt\n",
        "!git clone https://github.com/yhgon/segan-pyt.git"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'segan-pyt'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)   \u001b[K\rremote: Counting objects:  22% (2/9)   \u001b[K\rremote: Counting objects:  33% (3/9)   \u001b[K\rremote: Counting objects:  44% (4/9)   \u001b[K\rremote: Counting objects:  55% (5/9)   \u001b[K\rremote: Counting objects:  66% (6/9)   \u001b[K\rremote: Counting objects:  77% (7/9)   \u001b[K\rremote: Counting objects:  88% (8/9)   \u001b[K\rremote: Counting objects: 100% (9/9)   \u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 164 (delta 3), reused 0 (delta 0), pack-reused 155\u001b[K\n",
            "Receiving objects: 100% (164/164), 2.14 MiB | 4.98 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aTn1Zc2WGPvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## prepare dataset \n",
        "down sampling with librosa and make numpy\n",
        "- train dataset  : downsampling 11572 wav  and generate  48640 np files \n",
        "- test dataset   : downsampling     824 wav and generate 2805 np files  \n",
        "\n",
        "it would takes  about 6 minutes. you could see the log : \n",
        "\n",
        "```\n",
        "Serialize and down-sample train audios: 100% 11572/11572 [01:28<00:00, 131.34it/s]\n",
        "Verify serialized train audios: 100% 48640/48640 [01:20<00:00, 606.76it/s]\n",
        "Serialize and down-sample test audios: 100% 824/824 [02:50<00:00,  4.18it/s]\n",
        "Verify serialized test audios: 100% 2805/2805 [00:01<00:00, 2235.37it/s]\n",
        "CPU times: user 5.38 s, sys: 1.33 s, total: 6.71 s\n",
        "Wall time: 5min 42s\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "7WdUuQj50qWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "51863452-f3f7-40e3-b195-bc5268e5b44a"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python segan-pyt/data_preprocess.py"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serialize and down-sample train audios: 100% 11572/11572 [01:28<00:00, 131.34it/s]\n",
            "Verify serialized train audios: 100% 48640/48640 [01:20<00:00, 606.76it/s]\n",
            "Serialize and down-sample test audios: 100% 824/824 [02:50<00:00,  4.18it/s]\n",
            "Verify serialized test audios: 100% 2805/2805 [00:01<00:00, 2235.37it/s]\n",
            "CPU times: user 5.38 s, sys: 1.33 s, total: 6.71 s\n",
            "Wall time: 5min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sg60EN0SYwS8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir results\n",
        "!mkdir epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-fbMv8y4uzv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "performance in COLAB with K80 \n",
        "```\n",
        "with batch  4 100% 12160/12160 [2:29:28<00:00,  1.37it/s]\n",
        "with batch  8   0%    19/ 6080 [00:21<1:54:24,  1.13s/it\n",
        "with batch 16   1%    22/ 3040 [00:44<1:41:04,  2.01s/it]\n",
        "with batch 32   0%     0/ 1520 [00:00<?, ?it/s]ERROR: insufficient shared memory\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "XSZMsvzt2N6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "bf8b1a04-fdfc-4771-a201-b57c601e1adf"
      },
      "cell_type": "code",
      "source": [
        "!python ./segan-pyt/main.py --batch_size 16 --num_epochs 64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data...\n",
            "# generator parameters: 75453878\n",
            "# discriminator parameters: 97473194\n",
            "  0% 0/3040 [00:00<?, ?it/s]./segan-pyt/main.py:94: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  .format(epoch + 1, clean_loss.data[0], noisy_loss.data[0], g_loss.data[0], g_cond_loss.data[0]))\n",
            "Epoch 1: d_clean_loss 0.0020, d_noisy_loss 0.0000, g_loss 100.5021, g_conditional_loss 100.0026: 100% 3040/3040 [1:41:37<00:00,  2.00s/it]\n",
            "Test model and save generated audios:   0% 0/176 [00:00<?, ?it/s]./segan-pyt/main.py:99: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  z = nn.init.normal(torch.Tensor(test_noisy.size(0), 1024, 8))\n",
            "Test model and save generated audios: 100% 176/176 [00:22<00:00,  7.80it/s]\n",
            "Epoch 2: d_clean_loss 0.0000, d_noisy_loss 0.0000, g_loss 100.4992, g_conditional_loss 99.9996: 100% 3040/3040 [1:41:24<00:00,  2.00s/it]\n",
            "Test model and save generated audios: 100% 176/176 [00:22<00:00,  7.84it/s]\n",
            "Epoch 3: d_clean_loss 0.0000, d_noisy_loss 0.0000, g_loss 100.5049, g_conditional_loss 100.0049: 100% 3040/3040 [1:41:40<00:00,  2.02s/it]\n",
            "Test model and save generated audios: 100% 176/176 [00:22<00:00,  7.73it/s]\n",
            "Epoch 4: d_clean_loss 0.0000, d_noisy_loss 0.0000, g_loss 100.5091, g_conditional_loss 100.0091:  11% 323/3040 [10:54<1:31:43,  2.03s/it]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}